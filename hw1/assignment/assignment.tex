\documentclass[12pt, oneside]{article}
\usepackage[T2A]{fontenc}

\usepackage[
  letterpaper,
  left=2.5cm,
  right=2.5cm,
  top=2.5cm,
  bottom=1.5cm
]{geometry}

\usepackage[unicode]{hyperref}
\hypersetup{
    colorlinks=true,
    % allcolors=black
}

\usepackage{fancyhdr}
\fancyhf{}
\pagestyle{fancy}
\fancyhead[L]{MIPT CDS}
\fancyhead[C]{Reinforcement Learning}
\fancyhead[R]{Spring 2023}

\author{Due March 23}
\title{Assignment 1}
\date{}


\begin{document}
\maketitle
\thispagestyle{fancy}

\section{Theoretical assignment: TD($\lambda$)}

Данное теоретическое задание посвящено алгоритму TD($\lambda$).

\textbf{Задание TD.1} Доказать, что если вычислять обновления весов на каждом шаге (без их применения), то суммарное обновление онлайнового и оффлайного варианта одинаково.

\textit{Под оффлайновым обновлением подразумевается оффлайновый алгоритм $\lambda$-отдачи. Под онлайновым обновлением подразумевается алгоритм TD($\lambda$). Подсказки можно найти в заданиях в конце главы 12.1 книги Саттона и Барто.}

\hyphenation{ис-тин-но}
\textbf{Задание TD.2} Доказать равнозначность оффлайного алгоритма $\lambda$-отдачи и истинно онлайнового алгоритма TD($\lambda$).

\textit{См. соответствующую главу 12.5 книги Саттона и Барто и статью \href{https://www.jmlr.org/papers/volume17/15-599/15-599.pdf}{van Seijen et al., 2016}}.

\section{Practical assignment: Imitation learning}

\hyphenation{стра-те-гии}
\hyphenation{уни-вер-си-те-та}
Цель задания --- реализовать и поэкспериментировать с алгоритмами имитационного обучения. По имеющимся демонстрациям предлагается обучить два варианта стратегии: с помощью алгоритма клонирования поведения (\href{https://youtu.be/HUzyjOsd2PA?list=PL_iWQOsE6TfURIIhCrlt-wj9ByIVpbfGc}{лекция по имитации поведения}) и алгоритма DAgger (см. \href{http://proceedings.mlr.press/v15/ross11a/ross11a.pdf}{оригинальная статья}), а затем сравнить их качество в средах на базе Mujoco. Данное задание основано на первом задании курса по \href{http://rail.eecs.berkeley.edu/deeprlcourse/}{Deep RL Университета Беркли}.

Код задания расположен по адресу
\begin{center}
    \href{https://github.com/pkuderov/mipt-rl-hw-2023}{https://github.com/pkuderov/mipt-rl-hw-2023}
\end{center}

\hyphenation{под-роб-нос-ти}
Есть возможность выполнять задание как локально, так и в Google Colab. Подробности, в том числе по установке зависимостей, вы найдете в README в репозитории.

\subsection{Behavioral Cloning}

Требуется заполнить пропуски в реализации алгоритма клонирования поведения. По адресу \verb|expert_data| содержатся \textit{pickled} данные экспертных стратегий. Рекомендуется начать ознакомление с точки запуска \verb|scripts/run_hw1.py| и затем продвигаться вглубь последовательно:

\begin{itemize}
    \item \verb|infrastructure/rl_trainer.py|,
    \item \verb|agents/bc_agent.py|,
    \item \verb|policies/MLP_policy.py|
    \item и далее, заполняя пропуски, отмеченные \verb|TODO|.
\end{itemize}

\textbf{Задание BC.1} Приведите результаты запуска вашей реализации в двух средах: Ant и любой другой. Требуется, чтобы в среде Ant качество было не хуже $25\%$ от качества эксперта. Пример запуска приведен в README. В качестве результатов приведите следующие данные: среднее значение (\verb|Eval_AverageReturn|) и стандартное отклонение отдачи (\verb|Eval_StdReturn|) по набору тестовых эпизодов.

\hyphenation{нес-коль-ко}
\textit{Обратите внимание, чтобы собрать данные по нескольким эпизодам, потребуется при запуске указать параметр суммарного количества шагов \texttt{eval\_batch\_size} в несколько раз больше параметра максимальной длины эпизода \texttt{ep\_len}. Собственно, их отношение и задает минимальное число эпизодов, которые войдут в выборку.}

\hyphenation{воз-мож-нос-ти}
\textit{Чтобы включить генерацию видео при логировании, воспользуйтесь аргументом запуска} \verb|--video_log_freq -1|. \textit{Удалите его при необходимости, но помните о возможности существенного замедления выполнения.}

\hyphenation{нап-ри-мер}
\textbf{Задание BC.2} Поэкспериментируйте с разными наборами гиперпараметров (например, число шагов обучения, объем предоставленных экспертных данных и т.п.). Для одного фиксированного гиперпараметра постройте график изменения качества работы агента [на одной из сред из первого задания] и поясните ваш выбор этого параметра.

\subsection{DAgger}

Заполнив все пропуски \verb|TODO|, вы также сможете запустить DAgger (см. аргументы запуска в README).

\hyphenation{го-ри-зон-таль-ны-ми}
\hyphenation{ги-пер-па-ра-мет-ры}
\textbf{Задание DA.1} Проведите запуски алгоритма на выбранных в задании 1 средах. Постройте график обучения DAgger'а --- число итераций алгоритма vs. средняя отдача за эпизод (с указанием стандартного отклонения). Добавьте в этот график горизонтальными линиями результаты эксперта и клонирования поведения. Укажи использованные гиперпараметры.

\section{Формат сдачи}

\hyphenation{пред-ло-же-нии}
Сдача предполагается в виде коммитов и комментариев к ним в соответствующем предложении изменения кода (pull request) в GitHub classroom (ссылка в тг канале курса).

\hyphenation{не-до-ста-ю-щих}
Ожидается, что сдача будет содержать непосредственно код заполненных вами недостающих частей выданной заготовки решения и логи финальных запусков (для каждого задания и каждой из использованных сред).

\hyphenation{от-лич-ной}
Оригинально все логи лежат в папке \verb|data|. Логи финальных запусков скопируйте из \verb|data| в отдельную папку \verb|run_logs| и отправьте вместе с вашим решением. Отличной альтернативой будет вместо этого снабдить решение ссылкой на отчет (report) в wandb, что потребует самостоятельно интегрировать использование данного сервиса в ваше решение.

\hyphenation{ре-ше-ние}
\hyphenation{аль-тер-на-ти-ва}
Также в сообщении к предложению необходимо добавить результаты, описание и решение по каждому из пунктов задания (в соответствии с тем, что оно требует). Разметка markdown позволяет и вставку картинок, и оформление табличек. Опционально, вы можете оформить результаты в виде отдельного файла .doc или .pdf и добавить их в посылку (commit), а в сообщении сослаться на этот файл. Не забудьте для каждого пункта задания код запуска, чтобы можно было воспроизвести ваши результаты.
\end{document}
